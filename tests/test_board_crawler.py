"""
ê²Œì‹œíŒ í¬ë¡¤ë§ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

import unittest
from unittest.mock import Mock, patch
from everytime_crawler import EverytimeCrawler


class TestBoardCrawling(unittest.TestCase):
    """ê²Œì‹œíŒ í¬ë¡¤ë§ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì…‹ì—…"""
        self.crawler = EverytimeCrawler()
    
    def test_board_map_exists(self):
        """ê²Œì‹œíŒ ID ë§¤í•‘ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        from everytime_crawler import BOARD_MAP
        
        self.assertIsInstance(BOARD_MAP, dict)
        self.assertIn("free", BOARD_MAP)
        self.assertIn("secret", BOARD_MAP)
        self.assertEqual(BOARD_MAP["free"], "ììœ ê²Œì‹œíŒ")
    
    def test_get_board_posts_parameters(self):
        """get_board_posts ë©”ì„œë“œì˜ íŒŒë¼ë¯¸í„° ê²€ì¦"""
        # ë©”ì„œë“œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        self.assertTrue(hasattr(self.crawler, 'get_board_posts'))
        
        # ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ í˜¸ì¶œ ê°€ëŠ¥í•œì§€ í™•ì¸ (ì‹¤ì œ ì‹¤í–‰ì€ í•˜ì§€ ì•ŠìŒ)
        method = getattr(self.crawler, 'get_board_posts')
        self.assertTrue(callable(method))
    
    def test_extract_post_info_methods(self):
        """ê²Œì‹œê¸€ ì •ë³´ ì¶”ì¶œ ë©”ì„œë“œë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        required_methods = [
            '_extract_posts_from_current_page',
            '_extract_single_post_info',
            'get_post_detail',
            'save_board_posts_to_csv',
            'save_board_posts_to_json',
            '_save_board_debug_info'
        ]
        
        for method_name in required_methods:
            self.assertTrue(
                hasattr(self.crawler, method_name),
                f"Method {method_name} not found"
            )
    
    def test_save_board_posts_empty_list(self):
        """ë¹ˆ ê²Œì‹œê¸€ ë¦¬ìŠ¤íŠ¸ ì €ì¥ ì‹œ ì²˜ë¦¬"""
        # CSV ì €ì¥ í…ŒìŠ¤íŠ¸
        self.crawler.save_board_posts_to_csv([])
        
        # JSON ì €ì¥ í…ŒìŠ¤íŠ¸  
        self.crawler.save_board_posts_to_json([])
        
        # ì˜ˆì™¸ê°€ ë°œìƒí•˜ì§€ ì•Šìœ¼ë©´ ì„±ê³µ
        self.assertTrue(True)
    
    @patch('builtins.open', create=True)
    @patch('json.dump')
    def test_save_board_posts_to_json(self, mock_json_dump, mock_open):
        """JSON ì €ì¥ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        mock_posts = [
            {
                'title': 'í…ŒìŠ¤íŠ¸ ê²Œì‹œê¸€',
                'author': 'í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì',
                'board_id': 'free',
                'created_time': '07/02'
            }
        ]
        
        self.crawler.save_board_posts_to_json(mock_posts, 'test.json')
        
        # íŒŒì¼ì´ ì—´ë ¸ëŠ”ì§€ í™•ì¸
        mock_open.assert_called_once()
        
        # JSON ë¤í”„ê°€ í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
        mock_json_dump.assert_called_once()
    
    def test_board_id_validation(self):
        """ê²Œì‹œíŒ ID ê²€ì¦"""
        from everytime_crawler import BOARD_MAP
        
        valid_boards = list(BOARD_MAP.keys())
        
        # ìœ íš¨í•œ ê²Œì‹œíŒ IDë“¤
        for board_id in ['free', 'secret', 'freshman']:
            self.assertIn(board_id, valid_boards)
        
        # ê²Œì‹œíŒ ì´ë¦„ë“¤ì´ í•œê¸€ì¸ì§€ í™•ì¸
        for board_name in BOARD_MAP.values():
            self.assertTrue(any(ord(char) > 127 for char in board_name))  # í•œê¸€ í¬í•¨ í™•ì¸


class TestBoardCrawlingIntegration(unittest.TestCase):
    """ê²Œì‹œíŒ í¬ë¡¤ë§ í†µí•© í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ í•„ìš”)"""
    
    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì…‹ì—…"""
        self.crawler = EverytimeCrawler()
        # ì‹¤ì œ í…ŒìŠ¤íŠ¸ëŠ” í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ëœ ê²½ìš°ë§Œ ì‹¤í–‰
        self.skip_if_no_credentials()
    
    def skip_if_no_credentials(self):
        """ì¸ì¦ ì •ë³´ê°€ ì—†ìœ¼ë©´ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ"""
        import os
        if not (os.getenv('EVERYTIME_USERNAME') and os.getenv('EVERYTIME_PASSWORD')):
            self.skipTest("í™˜ê²½ë³€ìˆ˜ì— ì—ë¸Œë¦¬íƒ€ì„ ê³„ì • ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
    
    def test_login_and_board_access(self):
        """ë¡œê·¸ì¸ í›„ ê²Œì‹œíŒ ì ‘ê·¼ í…ŒìŠ¤íŠ¸"""
        try:
            # WebDriver ì„¤ì •
            self.crawler.setup_driver(headless=True)
            
            # ë¡œê·¸ì¸ ì‹œë„
            login_success = self.crawler.login()
            
            if login_success:
                # ê²Œì‹œíŒ í˜ì´ì§€ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
                self.crawler.driver.get(f"{self.crawler.base_url}/free")
                
                # í˜ì´ì§€ê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
                self.assertIn("everytime", self.crawler.driver.current_url.lower())
                
                print("âœ… ë¡œê·¸ì¸ ë° ê²Œì‹œíŒ ì ‘ê·¼ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            else:
                self.skipTest("ë¡œê·¸ì¸ ì‹¤íŒ¨")
                
        except Exception as e:
            self.fail(f"í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            
        finally:
            if hasattr(self.crawler, 'driver') and self.crawler.driver:
                self.crawler.quit()


def run_board_crawling_demo():
    """ê²Œì‹œíŒ í¬ë¡¤ë§ ë°ëª¨ ì‹¤í–‰"""
    print("ğŸ¯ ê²Œì‹œíŒ í¬ë¡¤ë§ ë°ëª¨ ì‹œì‘")
    print("=" * 50)
    
    crawler = EverytimeCrawler()
    
    try:
        # í™˜ê²½ë³€ìˆ˜ í™•ì¸
        import os
        if not (os.getenv('EVERYTIME_USERNAME') and os.getenv('EVERYTIME_PASSWORD')):
            print("âŒ í™˜ê²½ë³€ìˆ˜ì— ì—ë¸Œë¦¬íƒ€ì„ ê³„ì • ì •ë³´ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            print("   EVERYTIME_USERNAME=your_username")
            print("   EVERYTIME_PASSWORD=your_password")
            return
        
        # WebDriver ì„¤ì •
        crawler.setup_driver(headless=False)
        
        # ë¡œê·¸ì¸
        if crawler.login():
            print("âœ… ë¡œê·¸ì¸ ì„±ê³µ!")
            
            # ììœ ê²Œì‹œíŒ 1í˜ì´ì§€ë§Œ í…ŒìŠ¤íŠ¸
            posts = crawler.get_board_posts("free", pages=1, delay=2)
            
            if posts:
                print(f"\nğŸ“Š í¬ë¡¤ë§ ê²°ê³¼: {len(posts)}ê°œ ê²Œì‹œê¸€")
                
                # ìƒ˜í”Œ ì¶œë ¥
                for i, post in enumerate(posts[:3], 1):
                    print(f"\n{i}. {post.get('title', 'N/A')}")
                    print(f"   ì‘ì„±ì: {post.get('author', 'N/A')}")
                    print(f"   ì‹œê°„: {post.get('created_time', 'N/A')}")
                    print(f"   ëŒ“ê¸€: {post.get('comment_count', '0')}ê°œ")
                
                # íŒŒì¼ ì €ì¥
                crawler.save_board_posts_to_json(posts, "data/demo_board_posts.json")
                print("\nğŸ’¾ ê²°ê³¼ê°€ data/demo_board_posts.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            else:
                print("âŒ ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print("âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨!")
            
    except Exception as e:
        print(f"âŒ ë°ëª¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        if crawler.driver:
            crawler.quit()
        
        print("\nâœ… ë°ëª¨ ì™„ë£Œ!")


if __name__ == "__main__":
    print("ğŸ§ª ê²Œì‹œíŒ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    print("=" * 50)
    
    # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("\n1ï¸âƒ£ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
    unittest.main(argv=[''], exit=False, verbosity=2)
    
    print("\n" + "=" * 50)
    
    # ë°ëª¨ ì‹¤í–‰
    print("\n2ï¸âƒ£ ë°ëª¨ ì‹¤í–‰...")
    run_board_crawling_demo()
