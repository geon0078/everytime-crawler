"""
ë¡œê·¸ì¸ ì—†ì´ ê³µê°œ ë°ì´í„° í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸
"""

import os
import sys
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from src.everytime_crawler.crawler import EverytimeCrawler

def test_public_access():
    """ë¡œê·¸ì¸ ì—†ì´ ê³µê°œ í˜ì´ì§€ ì ‘ê·¼ í…ŒìŠ¤íŠ¸"""
    crawler = EverytimeCrawler()
    
    try:
        print("ğŸ”§ WebDriver ì„¤ì • ì¤‘...")
        crawler.setup_driver(headless=False)
        
        print("ğŸŒ ì—ë¸Œë¦¬íƒ€ì„ ë©”ì¸ í˜ì´ì§€ ì ‘ê·¼...")
        crawler.driver.get("https://everytime.kr")
        time.sleep(3)
        
        print(f"í˜„ì¬ URL: {crawler.driver.current_url}")
        print(f"í˜ì´ì§€ ì œëª©: {crawler.driver.title}")
        
        # í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ· ì €ì¥
        crawler.driver.save_screenshot("debug/public_access_test.png")
        print("ìŠ¤í¬ë¦°ìƒ· ì €ì¥: debug/public_access_test.png")
        
        # HTML ì†ŒìŠ¤ ì €ì¥
        with open("debug/public_access_test.html", "w", encoding="utf-8") as f:
            f.write(crawler.driver.page_source)
        print("HTML ì†ŒìŠ¤ ì €ì¥: debug/public_access_test.html")
        
        # ê³µê°œ ê²Œì‹œíŒ ì ‘ê·¼ ì‹œë„
        print("\nğŸ¯ ê³µê°œ ê²Œì‹œíŒ ì ‘ê·¼ ì‹œë„...")
        public_boards = [
            "https://everytime.kr/389176",  # ììœ ê²Œì‹œíŒ (í•™êµë³„ë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            "https://everytime.kr/free",    # ììœ ê²Œì‹œíŒ
            "https://everytime.kr/389175",  # ë¹„ë°€ê²Œì‹œíŒ
            "https://everytime.kr/secret",  # ë¹„ë°€ê²Œì‹œíŒ
        ]
        
        for board_url in public_boards:
            try:
                print(f"\nğŸ“ {board_url} ì ‘ê·¼ ì¤‘...")
                crawler.driver.get(board_url)
                time.sleep(3)
                
                print(f"ì ‘ê·¼ í›„ URL: {crawler.driver.current_url}")
                
                # ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if "login" in crawler.driver.current_url:
                    print("âŒ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                else:
                    print("âœ… ê³µê°œ ì ‘ê·¼ ê°€ëŠ¥!")
                    
                    # ê²Œì‹œê¸€ ìš”ì†Œ ì°¾ê¸°
                    try:
                        # ë‹¤ì–‘í•œ ê²Œì‹œê¸€ ì„ íƒì ì‹œë„
                        article_selectors = [
                            "article",
                            ".article",
                            ".post",
                            ".list .article",
                            ".board .article",
                            "[class*='article']",
                            ".item",
                            ".list-item"
                        ]
                        
                        articles_found = 0
                        for selector in article_selectors:
                            try:
                                elements = crawler.driver.find_elements("css selector", selector)
                                if elements:
                                    print(f"ê²Œì‹œê¸€ ìš”ì†Œ ë°œê²¬: {selector} - {len(elements)}ê°œ")
                                    articles_found = len(elements)
                                    break
                            except:
                                continue
                        
                        if articles_found == 0:
                            print("ê²Œì‹œê¸€ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            
                            # HTML ì†ŒìŠ¤ ì €ì¥
                            filename = f"debug/board_access_{board_url.split('/')[-1]}.html"
                            with open(filename, "w", encoding="utf-8") as f:
                                f.write(crawler.driver.page_source)
                            print(f"HTML ì†ŒìŠ¤ ì €ì¥: {filename}")
                        
                    except Exception as e:
                        print(f"ê²Œì‹œê¸€ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                        
            except Exception as e:
                print(f"ê²Œì‹œíŒ ì ‘ê·¼ ì˜¤ë¥˜: {e}")
        
        time.sleep(5)  # ì‚¬ìš©ìê°€ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ëŒ€ê¸°
        
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
    
    finally:
        if crawler.driver:
            print("\nğŸ”’ ë¸Œë¼ìš°ì € ì¢…ë£Œ...")
            crawler.driver.quit()

if __name__ == "__main__":
    test_public_access()
