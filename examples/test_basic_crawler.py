#!/usr/bin/env python3
"""
ë¡œê·¸ì¸ ì—†ì´ ê³µê°œ ì •ë³´ë§Œ í¬ë¡¤ë§í•˜ëŠ” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import json
import time
from datetime import datetime
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ ê²½ë¡œì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from src.everytime_crawler.crawler import EverytimeCrawler


def test_crawler_without_login():
    """ë¡œê·¸ì¸ ì—†ì´ í¬ë¡¤ëŸ¬ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ì—ë¸Œë¦¬íƒ€ì„ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ (ë¡œê·¸ì¸ ì—†ìŒ)")
    print("=" * 50)
    
    crawler = None
    try:
        # í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        crawler = EverytimeCrawler()
        
        print("ğŸ”§ WebDriver ì„¤ì • ì¤‘...")
        crawler.setup_driver(headless=False)  # ë¸Œë¼ìš°ì € ë³´ì´ë„ë¡ ì„¤ì •
        
        # ë©”ì¸ í˜ì´ì§€ ì ‘ì† í…ŒìŠ¤íŠ¸
        print("ğŸŒ ë©”ì¸ í˜ì´ì§€ ì ‘ì† í…ŒìŠ¤íŠ¸...")
        crawler.driver.get("https://everytime.kr")
        time.sleep(3)
        
        print(f"í˜„ì¬ í˜ì´ì§€: {crawler.driver.current_url}")
        print(f"í˜ì´ì§€ ì œëª©: {crawler.driver.title}")
        
        # í˜ì´ì§€ ë¡œë”© í™•ì¸
        if "ì—ë¸Œë¦¬íƒ€ì„" in crawler.driver.title:
            print("âœ… ë©”ì¸ í˜ì´ì§€ ì ‘ì† ì„±ê³µ!")
        else:
            print("âŒ ë©”ì¸ í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨")
            
        # ëª‡ ì´ˆ ëŒ€ê¸°í•˜ì—¬ í˜ì´ì§€ í™•ì¸
        print("â³ í˜ì´ì§€ í™•ì¸ì„ ìœ„í•´ 5ì´ˆ ëŒ€ê¸°...")
        time.sleep(5)
        
        print("âœ… ê¸°ë³¸ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        print("ğŸ”’ ë¸Œë¼ìš°ì € ì¢…ë£Œ...")
        if crawler and crawler.driver:
            crawler.close()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    test_crawler_without_login()


if __name__ == "__main__":
    main()
